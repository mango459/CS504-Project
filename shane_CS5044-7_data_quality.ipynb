{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from src.static import DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Completeness\n",
    "Examining data for completeness involves a few methodical steps to ensure no critical components are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/mango/data/CS504/raw_loan_data.csv',\n",
       " '/home/mango/data/CS504/unit_data.csv',\n",
       " '/home/mango/data/CS504/loan_data.csv',\n",
       " '/home/mango/data/CS504/raw_unit_data.csv']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob(f'{DATA_DIR}/*.csv')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_51651/1648879077.py:1: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  loan_data = pd.read_csv(files[1])\n"
     ]
    }
   ],
   "source": [
    "loan_data = pd.read_csv(files[1])\n",
    "unit_data = pd.read_csv(files[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing values check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_pct(df:pd.core.frame.DataFrame, col:str):\n",
    "    return f'{round((df[col].isna().sum())*100/df.shape[0], 2)}%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_report(df, **kwargs):\n",
    "    print(f\"{kwargs.get('name', 'DF')+' '}Data Completeness'\")\n",
    "    for col in df.columns:\n",
    "        print(f'{col.capitalize()}: {null_pct(df, col)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With such few null values in the data we can examine the nulls by hand..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulls = loan_data.loc[loan_data.enterprise_flag.isna()]\n",
    "nulls.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks like there are 32 records missing pretty much everything, lets drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loan_data.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loan Data Data Completeness'\n",
      "Year: 0.0%\n",
      "Enterprise_flag: 0.0%\n",
      "Record_number: 0.0%\n",
      "Num_bedrooms: 0.0%\n",
      "Num_units: 0.0%\n",
      "Affordability_level: 0.0%\n",
      "Tenant_income_ind: 0.0%\n"
     ]
    }
   ],
   "source": [
    "null_report(loan_data, **{'name':'Loan Data'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit Data Data Completeness'\n",
      "Year: 0.0%\n",
      "Enterprise_flag: 0.0%\n",
      "Record_number: 0.0%\n",
      "Census_tract_2020: 0.0%\n",
      "Tract_income_ratio: 0.0%\n",
      "Affordability_cat: 0.0%\n",
      "Date_of_mortgage_note: 0.0%\n",
      "Purpose_of_loan: 0.0%\n",
      "Type_of_seller: 0.0%\n",
      "Federal_guarantee: 0.0%\n",
      "Tot_num_units: 0.0%\n"
     ]
    }
   ],
   "source": [
    "null_report(unit_data, **{'name':'Unit Data'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uniqueness\n",
    "A quick check confirms if there are duplicate records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    895729\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loan_data.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    107310\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit_data.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy\n",
    "We need to check that all values are accurate according to expected values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.datamappers import unit_data_dict, loan_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in unit_data:\n",
    "    if col in unit_data_dict.keys():\n",
    "        vals = unit_data[col].unique().tolist()\n",
    "        check_vals = [x for x in unit_data_dict[col].values()]\n",
    "        for val in vals:\n",
    "            if not val in check_vals:\n",
    "                print(f\"Unexpected value {val} in column {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in loan_data:\n",
    "    if col in loan_data_dict.keys():\n",
    "        vals = loan_data[col].unique().tolist()\n",
    "        check_vals = [x for x in loan_data_dict[col].values()]\n",
    "        for val in vals:\n",
    "            if not val in check_vals:\n",
    "                print(f\"Unexpected value {val} in column {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Atomicity\n",
    "Atomicity in this context relates to the indivudal ensuring that data transformations and updates are applied completely and correctly. When you're performing data cleaning, atomicity ensures that each operation (like removing duplicates, filling missing values, or correcting errors) is fully applied across all relevant records. If an operation fails partway through, atomicity ensures that the data reverts to its previous state, maintaining data integrity. The data pipeline scripts ensure this behavior by packaging all necessary operations into one executable that fails if all component operations do not run successfully. That is to say, if the logic of the data pipeline script is sound then the atomicity of the data is intact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conformity\n",
    "Visual inspection of the data dictionaries ensures that the data encodings have not changed much over time. Consistent definitions for all columns included in the 2023 data are present across all years of the data. There is however an additional column that does appear to be present in earlier versions of the data that is not included in later versions of the data. This means that the data does have slight conformity issues and will have to be addressed in the data pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
