{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "It is apparent in the data structures in the FHFA dataset that the data are presented in a way that requires significant manipulations to prepare it for modeling correctly. This script resolves issues presented by the data manipualtion such that modeling can occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.static import DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First the data must be read into the notebook and we perform ths step below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "mapped_data = pd.read_csv(f'{DATA_DIR}/mapped_data.csv', na_values=['.','NaN', 'None'])\n",
    "# sort values in a useful way\n",
    "mapped_data.sort_values(by=['year', 'enterprise_flag', 'record_number'], inplace=True)\n",
    "# ead in the last 5 years of data\n",
    "mapped_data = mapped_data[mapped_data.year >= (2023-5)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The variables of num_bedrooms and affordability level contain the information that needs to be brough to the surface.\n",
    "The first step is going to be one hot encoding the values of these into their own columns so that we can map unit counts for each individual loan record over them. Then when we get the aggregate some of these per property per year we will have unit counts for each bedroom count and affordability level per property per year. We will use these values to predict on later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['year', 'enterprise_flag', 'record_number', 'census_tract_2020',\n",
       "       'tract_income_ratio', 'affordability_cat', 'date_of_mortgage_note',\n",
       "       'purpose_of_loan', 'type_of_seller', 'federal_guarantee',\n",
       "       'tot_num_units', 'num_units', 'tenant_income_ind', 'num_bedrooms_0-1',\n",
       "       'num_bedrooms_>=2', 'affordability_level_>100%',\n",
       "       'affordability_level_>50, <=60%', 'affordability_level_>60, <=80%',\n",
       "       'affordability_level_>80, <=100%', 'affordability_level_>=0, <=50%'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode columns\n",
    "df = pd.get_dummies(\n",
    "    mapped_data,\n",
    "      columns=['num_bedrooms', 'affordability_level']\n",
    "    )\n",
    "\n",
    "# clean up new column names\n",
    "df.columns = df.columns.str.strip()\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to map the `num_units` for each record over each of the newly created columns so that when we aggregate the sum later we will get accurate counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a helper function\n",
    "def unit_count_transformer(df: pd.DataFrame, cols=list[str]) -> pd.DataFrame:\n",
    "    '''\n",
    "    map unit counts to certain columns. needs at least one column named `num_units` which is the\n",
    "        target of the transformation. i.e., values from `num_units` are mapped to columns in `cols`\n",
    "        arg.\n",
    "    arguments:\n",
    "        df: a dataframe of data needing to be transformed\n",
    "        cols: a list of specific column names that need to be worked on\n",
    "    returns: \n",
    "        a transformed dataframe\n",
    "    '''\n",
    "    # first create a copy so we arent working on the input dataframe\n",
    "    output = df.copy()\n",
    "    for col in cols:\n",
    "        # map the number of units in each loan record to the value of each input column\n",
    "        output[col] = output.index.map(\n",
    "            lambda x: output.loc[x]['num_units'] if output[col].loc[x] else 0\n",
    "            )\n",
    "    return output\n",
    "\n",
    "# execute the transformation\n",
    "df = unit_count_transformer(\n",
    "    df, ['num_bedrooms_0-1', 'num_bedrooms_>=2', 'affordability_level_>100%',\n",
    "         'affordability_level_>50, <=60%', 'affordability_level_>60, <=80%',\n",
    "         'affordability_level_>80, <=100%', 'affordability_level_>=0, <=50%']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we perform a massive grouping and aggregation. Rows which have the same `record_number` have columns which are *always* the same value within that same `record_number`. For example, given `record_number == 1` for a given `year` and `enterprise_flag`. That is to say, each of these individual record nubmer, year, enterprise flag combinations may have a value for `date_of_morgage_note` which does not vary despute multiple entries in our dataset for that combined index. These columns are identified and included in the grouping statement below because they are ingtegral to one record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this multistage grouping and aggregation creates 1 record with counts of units in certain columns\n",
    "df = df.groupby(\n",
    "    # define grouping columns for record grouping\n",
    "    ['year', 'enterprise_flag', 'record_number', 'census_tract_2020', 'tract_income_ratio',\n",
    "     'date_of_mortgage_note', 'purpose_of_loan', 'type_of_seller', 'federal_guarantee',\n",
    "     'tenant_income_ind', 'affordability_cat', 'tot_num_units']\n",
    "    # this next step identifies which columns we're going to sum up\n",
    "    )[['num_units', 'num_bedrooms_0-1', 'num_bedrooms_>=2', 'affordability_level_>100%',\n",
    "       'affordability_level_>50, <=60%', 'affordability_level_>60, <=80%',\n",
    "       'affordability_level_>80, <=100%', 'affordability_level_>=0, <=50%']].agg('sum').reset_index()\n",
    "\n",
    "print('Data aggregation yields a DataFrame containing aggregate counts of certain categories ',\n",
    "      df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finally prepare remaining categorical columns for modeling by finishing one hot encoding\n",
    "df = pd.get_dummies(\n",
    "    df,\n",
    "    columns=['census_tract_2020', 'tract_income_ratio', 'date_of_mortgage_note',\n",
    "             'purpose_of_loan', 'type_of_seller', 'federal_guarantee', 'tenant_income_ind',\n",
    "             'affordability_cat', 'tot_num_units'],\n",
    "    drop_first=True\n",
    "  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, since our data encapsulates the onset of COVID a very macro influential global event, it may be prudent to study what signal can be derived from a feature that encodes wether a record is pre or post covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create simple flag to tell the model about covid\n",
    "df['after_covid_ind'] = df.year >= 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save engineered data\n",
    "df.to_csv(f'{DATA_DIR}/preprocessed_data.csv', index=False)\n",
    "## End script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
